<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Introduction &mdash; Semi-Markov 1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Semi-Markov 1.0 documentation" href="index.html" />
    <link rel="up" title="Semi-Markov Library Manual" href="manual.html" />
    <link rel="next" title="Requirements and Installation" href="install.html" />
    <link rel="prev" title="Semi-Markov Library Manual" href="manual.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="install.html" title="Requirements and Installation"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="manual.html" title="Semi-Markov Library Manual"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Semi-Markov 1.0 documentation</a> &raquo;</li>
          <li><a href="manual.html" accesskey="U">Semi-Markov Library Manual</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Introduction</a></li>
<li><a class="reference internal" href="#organization-of-library">Organization of library</a></li>
<li><a class="reference internal" href="#acknowledgements">Acknowledgements</a></li>
<li><a class="reference internal" href="#availability-and-distribution">Availability and distribution</a></li>
<li><a class="reference internal" href="#background">Background</a><ul>
<li><a class="reference internal" href="#estimating-hazard-rates-from-binned-time-to-event-data">Estimating hazard rates from binned time-to-event data</a></li>
<li><a class="reference internal" href="#finite-state-machines">Finite state machines</a></li>
<li><a class="reference internal" href="#markov-chains">Markov chains</a></li>
<li><a class="reference internal" href="#markov-processes">Markov processes</a></li>
<li><a class="reference internal" href="#semi-markov-processes">Semi-Markov processes</a></li>
<li><a class="reference internal" href="#generalized-stochastic-petri-nets">Generalized stochastic Petri nets</a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples">Examples</a><ul>
<li><a class="reference internal" href="#frogs-on-lily-pads">Frogs on lily pads</a></li>
<li><a class="reference internal" href="#susceptible-infected-susceptible-sis-model-of-infectious-disease-transmission">Susceptible-infected-susceptible (SIS) model of infectious disease transmission</a></li>
<li><a class="reference internal" href="#management-of-dairy-herds">Management of dairy herds</a></li>
</ul>
</li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="manual.html"
                        title="previous chapter">Semi-Markov Library Manual</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="install.html"
                        title="next chapter">Requirements and Installation</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/intro.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>The <tt class="docutils literal"><span class="pre">Semi-Markov</span></tt> library is designed to streamline the process of
creating efficient simulations of a large class of systems called
semi-Markov processes <a class="reference internal" href="#howard-1971" id="id1">[Howard:1971]</a>.  Semi-Markov processes naturally
arise in many contexts including epidemiology <a class="reference internal" href="#viet-2004" id="id2">[Viet:2004]</a>, physiology,
ecology, atmospheric sciences, reliability engineering and risk
management.  This broad range of applications suggest the value of
designing a generic library for simulating complex semi-Markov
processes, independent of the particular application area.</p>
<p>The unifying idea on which this library is based is that there
typically are many different pathways for a complex system to evolve
between timesteps.  Each pathway can be viewed as an elementary
stochastic process with a user specified time-dependent transition
rates and a rule for modifying the overall internal state of the
system.  At each instant of time, these elementary processes
&#8220;compete&#8221;, figuratively speaking, for the chance to change the state
of the whole system.  Each time step in the simulation corresponds to
an event &#8211; a &#8220;winner&#8221; is selected thus changing the internal state of
the system and the sampling from the corresponding statistical
distribution to determine the time increment.  This competing process
view provides a framework for users to develop simulations for complex
models in an incremental manner.</p>
<p>It is easy to show that competing processes with exponentially
distributed transition times have time-independent transition rates.
This is the norm in some application areas such as chemical kinetics.
In contrast, it is manifestly inappropriate for many biological
applications such as physiology, ecology and epidemiology.  For
example, a classic paper by Stocks <a class="reference internal" href="#stocks-1931" id="id3">[Stocks:1931]</a> clearly shows that
the latent period for measles (the distribution times between
infection and the appearance of symptoms) does not follow an
exponential distribution. Stocks&#8217; raw data from cases in London circa
1931 is presented in <a class="reference internal" href="#latent-period"><em>Figure 1</em></a>.</p>
<div class="figure align-center" id="latent-period">
<a class="reference internal image-reference" href="_images/Stocks_latent_period_counts.svg"><img src="_images/Stocks_latent_period_counts.svg" /></a>
<p class="caption">Figure 1</p>
</div>
<p>This simple example shows that exclusive reliance on exponential
distributions may lead systematic biases in stochastic simulations of
epidemiological process.  Therefore, this library provides support for
general semi-Markov models based on competing processes with general
probability distributions of transition times.</p>
</div>
<div class="section" id="organization-of-library">
<h1>Organization of library<a class="headerlink" href="#organization-of-library" title="Permalink to this headline">¶</a></h1>
<p>It is implemented using three cooperating layers:</p>
<ul class="simple">
<li><strong>Finite state machine</strong>: High-level interface for initializing the
system, iterating over time steps and gathering relevant tracing
data for post-processing.</li>
<li><strong>Semi-Markov process</strong>: &#8220;Middleware&#8221; responsible for statistically
unbiased choice among all possible competing processes at a given
time step.</li>
<li><strong>Generalized stochastic Petri net</strong>: Low-level coordination and
bookkeeping related to the user-defined competing processes
including distributions of transition times, modification of system
state and various dependence relationships.</li>
</ul>
<p>This organization has many practical advantages:</p>
<ul class="simple">
<li>The semi-Markov process layer can be viewed as a very efficient,
general purpose, stochastic simulation engine that supports
arbitrary statistical distributions for event times.  This layer
contains no model-specific user code, thus can be independently
verified and validated.</li>
<li>Typically, the itself model is completely defined by instantiating
components of the Petri net.  The Petri net layer automates most of
the tedious and error-prone bookkeeping steps associated with the
execution of the model.</li>
<li>The library strictly enforces a separation of the static components
that define the structural aspects of the model and the dynamic
components that define the evolving state during a simulation.  This
separation makes it possible to detect many critical programming
errors associated with multithreading at compile time.</li>
</ul>
</div>
<div class="section" id="acknowledgements">
<h1>Acknowledgements<a class="headerlink" href="#acknowledgements" title="Permalink to this headline">¶</a></h1>
<p>This library was created by the Analytical Framework for Infectious
Disease Dynamics (AFIDD) group at Cornell University in conjunction
with the USDA Agricultural Research Service.  The AFIDD group is
supported by funds from the Department of Homeland Security.</p>
</div>
<div class="section" id="availability-and-distribution">
<h1>Availability and distribution<a class="headerlink" href="#availability-and-distribution" title="Permalink to this headline">¶</a></h1>
<p>This library is in the public domain.</p>
</div>
<div class="section" id="background">
<h1>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h1>
<p>Throughout this section, <span class="math">\(\bf{X}\)</span> will be assumed to
real-valued random variable.  For example, <span class="math">\(\bf{X}\)</span> could
represent latent periods for measles as discussed above.  The central
object in statistical modeling of dynamics is the <em>distribution</em></p>
<div class="math">
\[F_{X}(t) = \mathcal{P}\left[x \le t\right]\]</div>
<p>assuming <span class="math">\(F_{X}(\infty) = 1\)</span>.  The quantity</p>
<div class="math">
\[\begin{split}G_{X}(t) = \mathcal{P}\left[x&gt;t\right] = 1 - F_{X}(t)\end{split}\]</div>
<p>will play a special role in the study of stochastic processes with
time-dependent rates.</p>
<p>If <span class="math">\(F_{X}(t)\)</span> is sufficiently smooth it is possible to define a
<em>density</em> as the derivative of <span class="math">\(F_{X}(t)\)</span> with respect to time</p>
<div class="math">
\[f_{X}(t) = \lim_{s\downarrow 0}
\frac{F_{X}(t+s)-F_{X}(t)}{s} =
\left.\frac{dF_{X}(t')}{dt'}\right|_{t'=t}\]</div>
<p>If <span class="math">\(F_{X}(t)\)</span> is differentiable then it is also possible to
define an instantaneous <em>hazard</em></p>
<div class="math">
\[\lambda_{X}(t) = \left.\frac{d\log
G_{X}(t')}{dt'}\right|_{t'=t} = \frac{f_{X}(t)}{G_{X}(t)}\]</div>
<p>Note, both <span class="math">\(f_{X}(t)\)</span> and <span class="math">\(\lambda_{X}(t)\)</span> are defined as
the derivative of unitless quantities, thus they carry units of
inverse time and can be thought of as frequencies or rates.</p>
<div class="section" id="estimating-hazard-rates-from-binned-time-to-event-data">
<h2>Estimating hazard rates from binned time-to-event data<a class="headerlink" href="#estimating-hazard-rates-from-binned-time-to-event-data" title="Permalink to this headline">¶</a></h2>
<p>It frequently happens that random samples of the real valued variables
such as <span class="math">\(\bf{X}\)</span> are actually analyzed on a discrete scale.  For
example Stocks&#8217; data on latent periods of measles in
<a class="reference internal" href="#latent-period"><em>Figure 1</em></a> is based on daily visits by patients.  The
(cumulative) distribution of <span class="math">\(\bf{X}\)</span> sampled at fixed
increments <span class="math">\(k=1,2,3,\ldots\)</span> is defined as</p>
<div class="math">
\[F_{X}(k) = \mathcal{P}\left[x\le k\right]\]</div>
<p>In the case of Stock&#8217;s data, <span class="math">\(F_{X}(k)\)</span> is the probability that
an individual who was infected on day <span class="math">\(0\)</span> will first develop
symptoms sometime before day <span class="math">\(k\)</span>.  Specialized statistical methods
are required to estimate survival curves from this kind of binned
counts.  The underlying problem can be exposed by careful
consideration of the data in <a class="reference internal" href="#latent-period"><em>Figure 1</em></a>.</p>
<div class="figure" id="latent-period-ecdf">
<a class="reference internal image-reference" href="_images/Stocks_latent_period_ecdf.svg"><img src="_images/Stocks_latent_period_ecdf.svg" /></a>
</div>
<p>It is easy to see that the corresponding discrete density,
<span class="math">\(\hat{f}_{X}(k)\)</span>, can be expressed as the difference in adjacent
values of the distribution</p>
<div class="math">
\[\begin{eqnarray}
\hat{f}_{X}(k) & = & \mathcal{P}[X\le k] - \mathcal{P}[X \le k-1 ] \\
         & = & F_{X}(k) - F_{X}(k-1)
\end{eqnarray}\]</div><p>Thus, <span class="math">\(\hat{f}_{X}(k)\)</span> is the probability of events occuring
somewhere in an interval of time, not the instantaneous probability at
the specific point in time, <span class="math">\(t=k\)</span>.  The typical approach of
finding the parameters that give an fit to a gamma, lognormal or
Weibull density to the data in <a class="reference internal" href="#latent-period"><em>Figure 1</em></a> would yield
pointwise estimates of this interval-oriented probability.  This is
called the lifetable or actuarial approximation.  This approximation
is questionable for Stocks&#8217; data because the observed differences in
the number of cases on consecutive days can be quite large between
days 7 and 10.</p>
<p>An alternative statitical estimation procedure for obtaining
instantaneous estimates can be motivated by viewing the data in
<a class="reference internal" href="#latent-period"><em>Figure 1</em></a> as defining a piecewise constant function over
time intervals rather than the values of some continuous function at a
discrete set of time points.  This new perspective is illustrated in
<a class="reference internal" href="#latent-period-steps"><em>Figure 3</em></a>.</p>
<div class="figure align-center" id="latent-period-steps">
<a class="reference internal image-reference" href="_images/Stocks_latent_period_counts_step.svg"><img src="_images/Stocks_latent_period_counts_step.svg" /></a>
<p class="caption">Figure 3</p>
</div>
<p>The next problem is to choose a reliable statistical method to
estimate an   When there is only one process involved, the
one popular choice is to use the non-parametric Kaplan-Meier estimator
to compute an optimal piecewise constant survival curve and associated
confidence intervals as shown in <a class="reference internal" href="#latent-period-survival"><em>Figure 4</em></a>.  These
results were obtained in R using the function <cite>survfit</cite> from the
<cite>survival</cite> package.</p>
<div class="figure align-center" id="latent-period-survival">
<a class="reference internal image-reference" href="_images/Stocks_latent_period_survival.svg"><img src="_images/Stocks_latent_period_survival.svg" /></a>
<p class="caption">Figure 4</p>
</div>
<p>It straightforward to compute an instantaneous hazard and associated
confidence intervals in R from the estimates provided by the Kaplan-Meier
procedure using the <cite>insthaz</cite> function from the <cite>epiR</cite> package.  The
results are shown in <a class="reference internal" href="#latent-period-hazard"><em>Figure 5</em></a>.</p>
<div class="figure align-center" id="latent-period-hazard">
<a class="reference internal image-reference" href="_images/Stocks_latent_period_hazard.svg"><img src="_images/Stocks_latent_period_hazard.svg" /></a>
<p class="caption">Figure 5</p>
</div>
<p>Note, survival estimates are often unreliable at long times when the
number of individuals is necessarily small.</p>
</div>
<div class="section" id="finite-state-machines">
<h2>Finite state machines<a class="headerlink" href="#finite-state-machines" title="Permalink to this headline">¶</a></h2>
<p>A <em>finite state machine</em> is a mathematical model for a particularly
simple class of computing systems.  At a conceptual level, a finite
state machine can be considered a black box that receives a sequence
of input signal and produces an output signal for each input signal.
Internally, the black box maintains a <em>state</em> &#8211; some sort of finite
summary representation of the sequence of input signals encountered so
far.  For each input signal, the box performs two operations.  In both
cases, the decision depends on the current internal state and the
identity of the input signal just received.</p>
<ul class="simple">
<li><strong>Choose next state</strong></li>
<li><strong>Generate output token</strong></li>
</ul>
<p>It is helpful to view the finite state machine layer as a mechanism to
simulate a <em>Markov chain</em> or <em>Markov process</em>.</p>
</div>
<div class="section" id="markov-chains">
<h2>Markov chains<a class="headerlink" href="#markov-chains" title="Permalink to this headline">¶</a></h2>
<p>Roughly speaking, a <em>Markov chain</em>, <span class="math">\(\bf{X}\)</span>, is a probabilistic
system that makes random jumps among a finite set of distinct states,
<span class="math">\(s_0, s_1, s_2, \ldots, s_N\)</span> such that the probability of
choosing the next state, <span class="math">\(X_{n+1}\)</span> depends only on the current
state, <span class="math">\(X_n\)</span>.  In mathematical terms, the conditional
probabilities for state transitions must satisfy</p>
<div class="math">
\[\mathcal{P}[X_{n+1} = s_{l} | X_0=s_i, X_1=s_j, \ldots, X_n=s_k] =
\mathcal{P}[X_{n+1} = s_{l} | X_{n}=s_k]\]</div>
<p>Since more distant history does not affect future behavior, Markov
chains are sometimes characterized as <em>memoryless</em>.</p>
<p>It is not hard to show that this relation can be iterated to compute
the conditional probabilities for multiple time steps</p>
<div class="math">
\[\mathcal{P}[X_{n+2} = s_{m} | X_n=s_k] = \sum_{l} \mathcal{P}[X_{n+2} = s_{m} |
X_{n+1}=s_l] \mathcal{P}[X_{n+1} = s_{l} | X_{n}=s_k]\]</div>
<p>Note, the transition probabilities <span class="math">\(\mathcal{P}[X_{n+1} = s_{l} |
X_{n}=s_k]\)</span> may depend on time (the index <span class="math">\(n\)</span>).  These so-called
time-inhomogeneous Markov chains arise when the system of interest is
driven by external entities.  Chains with time-independent conditional
transition probabilities are called time-homogeneous.  The dynamics of
a time-homogeneous Markov chain is completely determined by the
initial state and the transition probabilities.  All processes
considered in this document are time-homogeneous.</p>
</div>
<div class="section" id="markov-processes">
<h2>Markov processes<a class="headerlink" href="#markov-processes" title="Permalink to this headline">¶</a></h2>
<p>The simplest way to think of a <em>Markov process</em> is a generalization of
the Markov chain such that time is viewed as continuous rather than
discrete.  As a result, it makes sense to record the times at which
the transitions occur as part of the process itself.</p>
<p>The first step in this generalization is to define a stochastic
process <span class="math">\(\bf{Y}\)</span> that includes the transition times as well as
the state, <span class="math">\(Y_{n} = (s_{j},t_{n})\)</span>.</p>
<p>The second step is to treat time on a truly continuous basis by
defining a new stochastic process, <span class="math">\(\bf{Z}\)</span>, from <span class="math">\(\bf{Y}\)</span>
by the rule <span class="math">\(Z_{t} = s_k\)</span> in the time interval <span class="math">\(t_n \le t
&lt; t_{n+1}\)</span> given <span class="math">\(Y_{n} = (s_k, t_n)\)</span> .  In other words,
<span class="math">\(\bf{Z}_{t}\)</span> is a piecewise constant version of <span class="math">\(\bf{Y}\)</span>
as shown in <a class="reference internal" href="#piecewise-z"><em>Figure 2.  Realization of a continuous time stochastic process and
associated Markov chain.</em></a></p>
<div class="figure align-center" id="piecewise-z">
<a class="reference internal image-reference" href="_images/piecewise_Z.svg"><img src="_images/piecewise_Z.svg" /></a>
<p class="caption">Figure 2.  <strong>Realization of a continuous time stochastic process and
associated Markov chain.</strong></p>
</div>
<p>A realization of the process <span class="math">\(\bf{Y}\)</span> is defined by the closed
diamonds (left end points) alone.  Similarly, a realization of the
process <span class="math">\(\bf{Z}_t\)</span> is illustrated by the closed diamonds and
line segments.  The closed and open diamonds at the ends of the line
segment indicate that the segments include the left but not the right
end points.</p>
<p>The memoryless property for Markov processes is considerably more
delicate than in the case of Markov chain because the time variable is
continuous rather than discrete.  In the case of <span class="math">\(\bf{Y}\)</span>, the
conditional probabilities for state transitions of must satisfy</p>
<div class="math">
\[\mathcal{P}[Y_{n+1} = (s_{l},t_{n+1}) | Y_0=(s_i, t_0), Y_1=(s_j, t_1),
\ldots, Y_n=(s_k, t_n)] =
\mathcal{P}[Y_{n+1} = (s_{l}, t_{n+1}) | Y_{n}=(s_k, t_{n})]\]</div>
<p>The proper generalization of the requirement of time-homeogeneity
stated previously for Markov chains is that joint probability
be unchanged by uniform shifts in time</p>
<div class="math">
\[\mathcal{P}[Z_{t+\tau} | Z_{s+\tau}] = \mathcal{P}[Z_{t} | Z_{s} ]\]</div>
<p>for <span class="math">\(0&lt;s&lt;t\)</span> and <span class="math">\(\tau &gt; 0\)</span>.  Stochastic processes with
shift invariant state transition probabilities are called
<em>stationary</em>.</p>
<p><strong>*This section is incomplete*</strong></p>
</div>
<div class="section" id="semi-markov-processes">
<h2>Semi-Markov processes<a class="headerlink" href="#semi-markov-processes" title="Permalink to this headline">¶</a></h2>
<p>As the name suggests, a <strong>semi-Markov process</strong> is generalization of a
Markov process.</p>
<p><strong>*This section is incomplete*</strong></p>
</div>
<div class="section" id="generalized-stochastic-petri-nets">
<h2>Generalized stochastic Petri nets<a class="headerlink" href="#generalized-stochastic-petri-nets" title="Permalink to this headline">¶</a></h2>
<p>A <strong>generalized stochastic Petri net</strong> (GSPN) is a formal way to
specify a a system of interacting, competing processes. Different
organisms can compete, but, for this system, the likelihood of
infecting a neighbor versus the likelihood of recovery are seen as
competing, as well.</p>
<p>Define a system by placing <em>tokens</em> at <em>places,</em> the way you would
put checkers on a game board. Each place represents a sub-state of
the system, such as herd of animals. Five tokens on a place representing
a herd means the herd has five animals.</p>
<p><em>Transitions</em> compete to move the tokens. Each transition is
an independent process. (We explain later how and why independent processes
are able to represent biological processes that are clearly dependent.)
Only transitions change the state. Each one triggers according to its
own internal clock. This library can model non-exponential distributions
of firing times.</p>
</div>
</div>
<div class="section" id="examples">
<h1>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h1>
<p>To gain more insight into the practical application of these rather
abstract ideas, consider the following concrete examples.</p>
<div class="section" id="frogs-on-lily-pads">
<h2>Frogs on lily pads<a class="headerlink" href="#frogs-on-lily-pads" title="Permalink to this headline">¶</a></h2>
<p>In the preface to his classic book on semi-Markov
processes <a class="reference internal" href="#howard-1971" id="id4">[Howard:1971]</a>, Howard offers the following guidance
to readers:</p>
<blockquote class="epigraph">
<div><em>It is often said that good ideas are simple; the Markov
process is no exception.  In fact there is no problem in
this book that cannot be made clear to a child.  The
device we use to make such expositions simple is a pond
covered by lily pads among which a frog may jump.
Although his jumps may be random, the frog never falls
into the water...it should be helpful to all readers to
discuss each chapter using the lily pond analogy.</em></div></blockquote>
<p>While one may question Howard&#8217;s view of the abstract reasoning
capabilities of children, his advice about frogs and lily pads is
sound.</p>
<p>Imagine a pond with a frog jumping among seven lily pads as in Figure
<a class="reference internal" href="#pond"><em>Figure 3.  Location of lily pads in a hypothetical pond.</em></a>.  The probability of jumping to pad <span class="math">\(i\)</span> at or
before time <span class="math">\(t=\tau\)</span> given that the frog arrived at pad <span class="math">\(j\)</span>
at <span class="math">\(t=0\)</span> is given by</p>
<div class="math">
\[C_{ij}(\tau) = q_{ij} H_{ij}(\tau)\]</div>
<p>where <span class="math">\(q_{ij}\)</span> is marginal probability of jumping from pad
<span class="math">\(j\)</span> to pad <span class="math">\(i\)</span> at any time and <span class="math">\(H_{ij}(\tau)\)</span> is the
conditional distribution of jump times given that the frog arrived at
pad <span class="math">\(j\)</span> at <cite>t=0</cite> and the destination will be pad <span class="math">\(j\)</span>.  It
is convenient to assume that the frog will actually move at every
jump, i.e.,</p>
<div class="math">
\[\sum_{k\ne j} q_{kj} = 1\]</div>
<p>and <span class="math">\(q_{jj} = 0\)</span>.</p>
<div class="figure align-center" id="pond">
<a class="reference internal image-reference" href="_images/pond.svg"><img src="_images/pond.svg" /></a>
<p class="caption">Figure 3.  Location of lily pads in a hypothetical pond.</p>
</div>
<p><strong>*This section is incomplete*</strong></p>
</div>
<div class="section" id="susceptible-infected-susceptible-sis-model-of-infectious-disease-transmission">
<h2>Susceptible-infected-susceptible (SIS) model of infectious disease transmission<a class="headerlink" href="#susceptible-infected-susceptible-sis-model-of-infectious-disease-transmission" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="management-of-dairy-herds">
<h2>Management of dairy herds<a class="headerlink" href="#management-of-dairy-herds" title="Permalink to this headline">¶</a></h2>
<p>As an example, let&#8217;s look at a simple model for the farm management of
dairy cows, following <a class="reference internal" href="#viet-2004" id="id5">[Viet:2004]</a>.  There are four groups, calves,
heifers before breeding (heifer 1), heifers ready for breeding (heifer
2), and dairy cows which give birth to new calves. We might make a
sketch as shown here.</p>
<a class="reference internal image-reference" href="_images/bvd_gist.svg"><div align="center" class="align-center"><img alt="Cow management has four stages, calf, heifer 1, heifer 2, and dairy." src="_images/bvd_gist.svg" /></div>
</a>
<p>We may have several different goals for this model. We may want to ask
how quickly a disease might spread through a herd, on average. We may
want to parameterize a differential equation model for changes in
herd sizes given economic conditions. The data for this model, though,
come in the form of charts of how many days it took a particular set
of heifers to give birth after their first insemination. It comes in
the form of rules that farmers with too many calves to fit in the pen
sell the rest. We are going to use a GSPN to express this model
in terms of the measured quantities.</p>
<p>The chart above shows a set of states for the cow, but it isn&#8217;t clear,
for instance, about the number of ways a cow can leave the farm.
There can be two ways a cow can <em>transition</em> to leaving the
farm: sale or death.</p>
</div>
</div>
<div class="section" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h1>
<table class="docutils citation" frame="void" id="howard-1971" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Howard:1971]</td><td><em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id4">2</a>)</em> R. A. Howard, &#8220;Dynamic Probabilistic Systems. Vol. II:
Semi-Markov and Decision Processes&#8221; (J. Wiley and Sons, 1971).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="stocks-1931" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[Stocks:1931]</a></td><td>P. Stocks, &#8220;Incubation period of measles,&#8221; British
Medical Journal 1(3655): p. 157.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="viet-2004" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Viet:2004]</td><td><em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id5">2</a>)</em> A.-F. Viet, C. Fourichon, H. Seegers, C. Jacob,
and C. Guihenneuc-Jouyaux, &#8220;A model of the spread of the bovine
viral-diarrhoea virus within a dairy herd.,&#8221; Prev. Vet. Med., vol. 63,
no. 3–4, pp. 211–36, May 2004.</td></tr>
</tbody>
</table>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="install.html" title="Requirements and Installation"
             >next</a> |</li>
        <li class="right" >
          <a href="manual.html" title="Semi-Markov Library Manual"
             >previous</a> |</li>
        <li><a href="index.html">Semi-Markov 1.0 documentation</a> &raquo;</li>
          <li><a href="manual.html" >Semi-Markov Library Manual</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2014, Andrew Dolgert, David Schneider.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>